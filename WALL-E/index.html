
<html>

<head>
    <link rel="StyleSheet" href="style.css" type="text/css" media="all">
    <title>WALL-E: Embodied Robotic WAiter Load Lifting with Large Language Model</title>
    <meta property="og:title" content="WALL-E: Embodied Robotic WAiter Load Lifting with Large Language Model">
    <!-- Place this tag in your head or just before your close body tag. -->
    <script async defer src="https://buttons.github.io/buttons.js"></script>
</head>
<body>
    <br>
    <div class="center-div">
        <span style="font-size:40px">WALL-E: <span style="color: gray;">E</span>mbodied Robotic <span style="color: gray;">WA</span>iter Load Lifting with
        <br>
        <span style="color: gray;">L</span>arge <span style="color: gray;">L</span>anguage Model</span>
    </div>

    <br>
    <table align="center" width="700px">
        <tbody>
            <tr>
                <td align="center" width="100px">
                    <div class="center-div">
                        <span style="font-size:22px"><a href="#">Tianyu Wang</a></span>
                    </div>
                </td>

                <td align="center" width="100px">
                    <div class="center-div">
                        <span style="font-size:22px"><a href="#">Yifan Li</a></span>
                    </div>
                </td>

                <td align="center" width="100px">
                    <div class="center-div">
                        <span style="font-size:22px"><a href="#">Haitao Lin</a></span>
                    </div>
                </td>

                <td align="center" width="100px">
                    <div class="center-div">
                        <span style="font-size:22px"><a href="#">Jingshun Huang</a></span>
                    </div>
                </td>
            </tr>
        </tbody>
    </table>
    <br>
    <table align="center" width="350px">
        <tbody>
            <tr>
                <td align="center" width="100px">
                    <div class="center-div">
                        <span style="font-size:22px"><a href="#">Xiangyang Xue</a></span>
                    </div>
                </td>
              
                <td align="center" width="100px">
                    <div class="center-div">
                        <span style="font-size:22px"><a href="https://yanweifu.github.io/">Yanwei Fu</a></span>
                    </div>
                </td>
            </tr>
        </tbody>
    </table>
    <br>
    <table align="center" width="700px">
        <tbody>
            <tr>
                <td align="center" width="100px">
                    <div class="center-div">     
                        <span style="font-size:22px">Fudan University</span>
                    </div>
                </td>
            </tr>
        </tbody>
    </table>
    <br><br>
    
    <div class="center-div">
        <img class="round" style="width: 95%; height: auto;" src="./resources/images/teaser.png">
    </div>
    <br>
    
    <hr>
    <div class="center-div">
        <h1>Abstract</h1>
    </div>
    <p style="text-align:justify">
        Enabling robots to understand language instructions and react accordingly to visual perception has been a long-standing goal in the robotics research community. Achieving this goal requires cutting-edge advances in natural language processing, computer vision, and robotics engineering. Thus, this paper mainly investigates the potential of integrating the most recent Large Language Models (LLMs) and existing visual grounding and robotic grasping system to enhance the effectiveness of the human-robot interaction. We introduce the WALL-E (Embodied Robotic WAiter load lifting with Large Language model) as an example of this integration. The system utilizes the LLM of ChatGPT to summarize the preference object of the users as a target instruction via the multi-round interactive dialogue. The target instruction is then forwarded to a visual grounding system for object pose and size estimation, following which the robot grasps the object accordingly. We deploy this LLM-empowered system on the physical robot to provide a more user-friendly interface for the instruction-guided grasping task. The further experimental results on various real-world scenarios demonstrated the feasibility and efficacy of our proposed framework.
    </p>
    <br>
    
    <hr>
    <div class="center-div">
        <h1 id="code">Pipeline</h1>
    </div>
    <div class="center-div">
        <img class="round" style="width: 95%; height: auto;" src="./resources/images/pipeline.png">
    </div>
    <br>
    
    <hr>
    <div class="center-div">
        <h1 id="paper">Paper and Code</h1>
    </div>
    <table align="center" width="600px">

        <tbody>
            <tr>
                <td>
                    <img class="layered-paper-big" style="height:175px" src="./resources/images/page1.png">
                </td>
                <td>
                    <span style="font-size:14pt">T. Wang, Y. Li, H. Lin, J. Huang, X. Xue, Y. Fu</span>
                    <br><br>
                    <b><span style="display:inline-block;width:600px;font-size:14pt">WALL-E: Embodied Robotic WAiter Load Lifting with Large Language Model</span></b>
                    <br><br>
                    <span style="font-size:14pt">Preprint. Under review (ICRA 2024).</span>
                    <br><br>
                    <span style="font-size:20px">
                        <a href="https://arxiv.org/abs/2308.15962">[arXiv]</a> &nbsp; &nbsp;
                        <a href="#">[Code]</a> &nbsp; &nbsp;
                    </span>
                </td>
            </tr>
        </tbody>
    </table>
    <br><br>

    <hr>
    <div class="center-div">
        <h1>Video demo</h1>
    </div>
    <div class="video-container">
        <video controls>
          <source src="./resources/videos/WALLE-Video-Demo.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
    </div>
    <hr>

    <div class="center-div">
        <h1 id="code">Visualization Cases</h1>
    </div>
    <div class="center-div">
        <img class="round" style="width: 95%; height: auto;" src="./resources/images/cases.png">
    </div>
    <br>
    <hr>
        
    <table align="center" width="980px">
        <tbody>
            <tr>
                <td>
                    <left>
                        <div class="center-div">
                            <h1>Acknowledgements</h1>
                        </div>
                        <div class="center-div">
                        Yanwei Fu is the corresponding author. If you are interested in this work, you can contact Professor Y. Fu via email: <span style="color: gray;">yanweifu@fudan.edu.cn</span>.
                        The website is modified from this <a href="https://walsvid.github.io/Pixel2MeshPlusPlus/">template</a>.
                        </div>
                    </left>
                </td>
            </tr>
        </tbody>
    </table>
    <br>



</body>

</html>
